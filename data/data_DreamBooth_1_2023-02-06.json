{"keyword": "DreamBooth", "count": 1, "datetime": "2023-02-06 00:35:31", "html": "<h4>DreamBooth_1条</h4><div score=\"0\" style=\"display: flex;\n                flex-direction: column;\n                outline: 1px solid gray;\n                margin: 12px;\n                padding: 24px;\n                font-size: 18px;\n                font-weight: 800;\n                color: black;\">谷歌抢先手发布视频生成类AIGC，网友：可以定制电影了 <br>\n                \n                <p style=\"background: yellow;\n                display: block;\n                width: fit-content;\n                margin: 0;\n                margin-top: 12px;\n                font-size: 12px;\">DreamBooth 新浪网</p> <p style=\"background: #dedede;\n                display: block;\n                width: fit-content;\n                font-size: 12px;\n                font-weight: 300;\">11h</p> <p style=\"display: block;\n                width: fit-content;\n                margin: 6px;\n                font-size: 14px;\n                font-weight: 300;\n                line-height: 24px;\">AIGC 已经火了很长时间了，出现了文本生成图像、文本生成视频、图像生成视频等广泛的应用场景，如今谷歌研究院的一项新研究可以让我们根据输入视频生成其他视频了！ 我们知道，生成模型和多模态视觉语言模型的进展已经为具备前所未有生成真实性和多样性的大型文本到图像模型铺平了道路。这些模型提供了新的创作过程，但仅限于合成新图像而非编辑现有图像。为了弥合这一差距，基于文本的直观编辑方法可以对生成和真实图像进行 ... <a href=\"https://finance.sina.com.cn/tech/roll/2023-02-05/doc-imyermet6526421.shtml\" style=\"                font-size: 15px;                font-weight: 800;                color: black;\" target=\"_blank\">  原文链接 </a></p></div>", "htmls": [{"score": 0, "html": "<div score=\"0\" style=\"display: flex;\n                flex-direction: column;\n                outline: 1px solid gray;\n                margin: 12px;\n                padding: 24px;\n                font-size: 18px;\n                font-weight: 800;\n                color: black;\">谷歌抢先手发布视频生成类AIGC，网友：可以定制电影了 <br>\n                \n                <p style=\"background: yellow;\n                display: block;\n                width: fit-content;\n                margin: 0;\n                margin-top: 12px;\n                font-size: 12px;\">DreamBooth 新浪网</p> <p style=\"background: #dedede;\n                display: block;\n                width: fit-content;\n                font-size: 12px;\n                font-weight: 300;\">11h</p> <p style=\"display: block;\n                width: fit-content;\n                margin: 6px;\n                font-size: 14px;\n                font-weight: 300;\n                line-height: 24px;\">AIGC 已经火了很长时间了，出现了文本生成图像、文本生成视频、图像生成视频等广泛的应用场景，如今谷歌研究院的一项新研究可以让我们根据输入视频生成其他视频了！ 我们知道，生成模型和多模态视觉语言模型的进展已经为具备前所未有生成真实性和多样性的大型文本到图像模型铺平了道路。这些模型提供了新的创作过程，但仅限于合成新图像而非编辑现有图像。为了弥合这一差距，基于文本的直观编辑方法可以对生成和真实图像进行 ... <a href=\"https://finance.sina.com.cn/tech/roll/2023-02-05/doc-imyermet6526421.shtml\" style=\"                font-size: 15px;                font-weight: 800;                color: black;\" target=\"_blank\">  原文链接 </a></p></div>"}], "data": [{"title": "谷歌抢先手发布视频生成类AIGC，网友：可以定制电影了", "imgurl": "", "author": "新浪网", "url": "https://finance.sina.com.cn/tech/roll/2023-02-05/doc-imyermet6526421.shtml", "snippet": "AIGC 已经火了很长时间了，出现了文本生成图像、文本生成视频、图像生成视频等广泛的应用场景，如今谷歌研究院的一项新研究可以让我们根据输入视频生成其他视频了！ 我们知道，生成模型和多模态视觉语言模型的进展已经为具备前所未有生成真实性和多样性的大型文本到图像模型铺平了道路。这些模型提供了新的创作过程，但仅限于合成新图像而非编辑现有图像。为了弥合这一差距，基于文本的直观编辑方法可以对生成和真实图像进行 ...", "date": "11h", "keyword": "DreamBooth", "score": 4, "html": "<div score=\"4\" class=\"score\" style=\"display: flex;\n                flex-direction: column;\n                outline: 1px solid gray;\n                margin: 12px;\n                padding: 24px;\n                font-size: 18px;\n                font-weight: 800;\n                color: black;\">谷歌抢先手发布视频生成类AIGC，网友：可以定制电影了 <br>\n                \n                <p style=\"background: yellow;\n                display: block;\n                width: fit-content;\n                margin: 0;\n                margin-top: 12px;\n                font-size: 12px;\">DreamBooth 新浪网</p> <p style=\"background: #dedede;\n                display: block;\n                width: fit-content;\n                font-size: 12px;\n                font-weight: 300;\">11h</p> <p style=\"display: block;\n                width: fit-content;\n                margin: 6px;\n                font-size: 14px;\n                font-weight: 300;\n                line-height: 24px;\">AIGC 已经火了很长时间了，出现了文本生成图像、文本生成视频、图像生成视频等广泛的应用场景，如今谷歌研究院的一项新研究可以让我们根据输入视频生成其他视频了！ 我们知道，生成模型和多模态视觉语言模型的进展已经为具备前所未有生成真实性和多样性的大型文本到图像模型铺平了道路。这些模型提供了新的创作过程，但仅限于合成新图像而非编辑现有图像。为了弥合这一差距，基于文本的直观编辑方法可以对生成和真实图像进行 ... <a href=\"https://finance.sina.com.cn/tech/roll/2023-02-05/doc-imyermet6526421.shtml\" style=\"                font-size: 15px;                font-weight: 800;                color: black;\" target=\"_blank\">  原文链接 </a></p></div>", "text": "谷歌抢先手发布视频生成类aigc，网友：可以定制电影了,aigc 已经火了很长时间了，出现了文本生成图像、文本生成视频、图像生成视频等广泛的应用场景，如今谷歌研究院的一项新研究可以让我们根据输入视频生成其他视频了！ 我们知道，生成模型和多模态视觉语言模型的进展已经为具备前所未有生成真实性和多样性的大型文本到图像模型铺平了道路。这些模型提供了新的创作过程，但仅限于合成新图像而非编辑现有图像。为了弥合这一差距，基于文本的直观编辑方法可以对生成和真实图像进行 ...,dreambooth", "is_zh": true, "event": {"公司/组织/机构": "谷歌研究院", "事件": "谷歌抢先手发布视频生成类aigc", "产品": "视频生成类aigc", "url": "https://finance.sina.com.cn/tech/roll/2023-02-05/doc-imyermet6526421.shtml"}}]}